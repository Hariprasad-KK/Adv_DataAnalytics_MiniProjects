{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hariprasad-KK/Adv_DataAnalytics_MiniProjects/blob/main/Copy_of_final_bert_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VSwNi-6s5s8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42004890-a985-4bd2-83cc-a1b5880c06b4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "id": "jHKMrB3Hgqp5",
        "outputId": "afc5945c-47bb-425a-9c6a-6a3ce50430e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.8/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.8/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.9.24)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2022.12.1)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.8/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.8/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.8/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.8/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.8/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "import pandas as pd\n",
        "import time\n",
        "import traceback\n",
        "import tweepy\n",
        "import re\n",
        "\n"
      ],
      "metadata": {
        "id": "5OpXyXr7gtsE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"YK6eUfcBsF8C0pM5PknXkS4Or\"\n",
        "api_secret = \"Kjp7OqHCqSzYarPMapCI1cJXsz6y9oSJwknydGBEy0ELxvIkBT\"\n",
        "access_token = \"1336204649989165057-cYfKk0s2uUoaIyDXwzZ8IHzhe3CghB\"\n",
        "access_secret = \"osVdZpG0WJOxQjYgHqj11ArZgeymrwT4QnwcILYTU2y2V\"\n",
        "\n",
        "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
        "auth.set_access_token(access_token, access_secret)\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)"
      ],
      "metadata": {
        "id": "WTRoKsz5gw1V"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets, text_query = [], 'spanish'\n",
        "count = 20\n",
        "\n",
        "try:\n",
        "    for tweet in api.search(q=text_query, count=count, result_type='recent',\n",
        "                           include_entities=True,\n",
        "                           monitor_rate_limit=True, \n",
        "                           wait_on_rate_limit=True):\n",
        "        # print(f\"Raw tweet: {tweet}\")\n",
        "        tweet_text_full, tweet_text_translated = \"\", \"\"\n",
        "\n",
        "        status = api.get_status(id = tweet.id, tweet_mode=\"extended\")\n",
        "        try:\n",
        "            tweet_text_full = status.retweeted_status.full_text\n",
        "        except AttributeError:  # Not a Retweet\n",
        "            tweet_text_full = status.full_text\n",
        "            \n",
        "        try:\n",
        "            tr = Translator()\n",
        "            \n",
        "            if tweet.lang and tweet.lang not in ['en']:\n",
        "\n",
        "\n",
        "                print(f\"Raw tweet: {tweet_text_full}\")\n",
        "                    \n",
        "                if tweet.text:\n",
        "                    translated = tr.translate(tweet_text_full)\n",
        "                    if translated:\n",
        "                        tweet_text = translated.__dict__()[\"text\"]\n",
        "            else:\n",
        "                tweet_text_translated = tweet_text_full\n",
        "                \n",
        "        except Exception as e:\n",
        "            traceback.print_exc()\n",
        "            pass\n",
        "        \n",
        "        tweets.append(( tweet_text_full))\n",
        "        \n",
        "        df_tr = pd.DataFrame(tweets, columns = ['Tweets'])\n",
        "        time.sleep(3)\n",
        "        \n",
        "    print(\"Completed.\")\n",
        "    \n",
        "except BaseException as e:\n",
        "    traceback.print_exc() "
      ],
      "metadata": {
        "id": "UfQS8WB1g2jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr.head(20)"
      ],
      "metadata": {
        "id": "QUXGjUZtg5GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yEFZNltjU7xS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet"
      ],
      "metadata": {
        "id": "xwNP4vCFg64L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Caps/\"\n",
        "\n",
        "df_tr.to_csv(path + 'tweets_full_translated.csv')"
      ],
      "metadata": {
        "id": "toF6gZcug9Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDqVJtZe5B1Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from googletrans import Translator\n",
        "from googletrans import LANGUAGES\n",
        "import pandas as pd\n",
        "# Reading the Live tweets data\n",
        "LiveTweets=pd.read_csv( '/content/drive/MyDrive/Caps/tweets_full_translated.csv', encoding='latin')\n",
        "print(LiveTweets.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()\n",
        "print(LiveTweets)"
      ],
      "metadata": {
        "id": "CjTiEVmCPDuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Translated_Tweets=[]\n",
        "for element in LiveTweets['Tweets']:\n",
        "  Translated_Tweets.append(translator.translate(element).text)\n",
        "LiveTweets['Translated_Tweets']=Translated_Tweets\n",
        "print(LiveTweets)"
      ],
      "metadata": {
        "id": "gJybFmOmP_zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LiveTweets.head(10)\n",
        "LiveTweets.drop(\"Unnamed: 0\",axis=1)\n",
        "LiveTweets.Tweets=LiveTweets.Tweets.str.replace(' ',' ')\n",
        "LiveTweets.Tweets =LiveTweets.Tweets.str.lstrip()\n",
        "LiveTweets.Tweets = LiveTweets.Tweets.str.rstrip()\n",
        "LiveTweets.Tweets = LiveTweets.Tweets.str.strip()\n",
        "#LiveTweets['Tweets'] = LiveTweets['Tweets'].str.replace('\\W', ' ', regex=True)\n",
        "print(LiveTweets)\n",
        "\n"
      ],
      "metadata": {
        "id": "-viNVrEZWhDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing mentions\n",
        "LiveTweets['Tweets'] = LiveTweets['Tweets'].str.replace(r'\\s*@\\w+', '', regex=True)\n",
        "LiveTweets['Tweets'] = LiveTweets['Tweets'].str.replace(r'\\s*#\\w+', '', regex=True)\n",
        "LiveTweets['Tweets'] = LiveTweets['Tweets'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n",
        "LiveTweets['Tweets'] = LiveTweets['Tweets'].str.replace('\\d+', '')\n",
        "LiveTweets['Tweets'] = LiveTweets['Tweets'].str.replace('\\W', ' ', regex=True)\n",
        "print(LiveTweets)"
      ],
      "metadata": {
        "id": "k-m80cRJM1EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing the library 'transformers' which contains BERT implementation\n",
        "!pip install transformers\n",
        "\n",
        "# installing the library tensorflow\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "6uYRYswO5HSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the pipeline module\n",
        "from transformers import pipeline\n",
        "\n",
        "# Downloading the sentiment analysis model\n",
        "SentimentClassifier = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "id": "4fVGPVP05L0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the sentiment analysis function for 3 sentences\n",
        "SentimentClassifier([\"I hope we get all these concepts! Its killing the neurons of our brain\",\n",
        "                     \"We had a nice experience in this trip\",\n",
        "                     \"Houston we have a problem\"\n",
        "])"
      ],
      "metadata": {
        "id": "bFXi_q-o5Paz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to call for the whole dataframe\n",
        "def FunctionBERTSentiment(inpText):\n",
        " return(SentimentClassifier(inpText)[0]['label'])\n",
        "\n",
        "# Calling the function\n",
        "FunctionBERTSentiment(inpText=\"Houston we have a problem\")"
      ],
      "metadata": {
        "id": "s0zsIHbD5WUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling BERT based sentiment score function for every tweet\n",
        "LiveTweets['Sentiment']=LiveTweets['Tweets'].apply(FunctionBERTSentiment)\n",
        "LiveTweets.head(10)\n"
      ],
      "metadata": {
        "id": "ZGzGk3dx5eqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the overall sentiment distribution\n",
        "import matplotlib.pyplot as plt\n",
        "fig, subPlot =plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
        "fig.suptitle(\"Sentiment analysis of Live Tweets\")\n",
        "\n",
        "# Grouping the data\n",
        "GroupedData=LiveTweets.groupby('Sentiment').size()\n",
        "\n",
        "# Creating the charts\n",
        "GroupedData.plot(kind='bar', ax=subPlot[0], color=['crimson', 'lightblue'])\n",
        "GroupedData.plot(kind='pie', ax=subPlot[1], colors=['crimson', 'lightblue'])"
      ],
      "metadata": {
        "id": "X8cNXAbp5myD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.remove('/content/drive/MyDrive/Caps/tweets_full_translated.csv')"
      ],
      "metadata": {
        "id": "x-5x11vjiSeL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}